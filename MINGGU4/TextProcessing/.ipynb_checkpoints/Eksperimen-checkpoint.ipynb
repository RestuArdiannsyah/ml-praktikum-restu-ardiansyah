{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3e8c3d6-42d2-40c6-81c0-4e1d7d0fb764",
   "metadata": {},
   "source": [
    "## PROCESING MENGGUNAKAN NTLK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740a116-0f46-4310-8a15-8a15d2b1f5db",
   "metadata": {},
   "source": [
    "##### dataset yang dgunakan: https://www.kaggle.com/datasets/waodeasriyani/data-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45fbcac-5583-4d2c-8a5f-bf8160b18a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import time\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f9094-032c-48e1-942d-49378313b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac817911-706c-419b-895d-4aeff9fca0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coba salah satu dari encoding ini:\n",
    "# df = pd.read_csv('Data_Sentiment_Pilpres_Setelah_Debat_1.csv', encoding='latin1')\n",
    "# atau:\n",
    "# df = pd.read_csv('Data_Sentiment_Pilpres_Setelah_Debat_1.csv', encoding='ISO-8859-1')\n",
    "# atau:\n",
    "df = pd.read_csv('Data_Sentiment_Pilpres_Setelah_Debat_1.csv', encoding='cp1252')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904ac81-41d4-4118-9dce-12d16e7988c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65513246-0b02-45e4-b080-d08b721a5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff370937-a3e2-4ab6-a10a-a1e7099c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1148c0-662a-48d7-8e13-d813a84e4e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8159da89-81cf-4e79-895c-7711f05088e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    #annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",'emphasis', 'censored'},\n",
    "    annotate={\"hashtag\"},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f5442-5262-43ff-a323-f198c88f875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# panggil ekphrasis\n",
    "\n",
    "def bersih_data(text):\n",
    "    return \" \".join(text_processor.pre_process_doc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e366c-98d7-4b3b-bb50-cf92c8fcea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fungsi dari AMS 01-03. silakan cek bagaimana saya merubah menjadi fungsi\n",
    "\n",
    "def non_ascii(text):\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "def remove_space_alzami(text):\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "def remove_emoji_alzami(text):\n",
    "    return ' '.join(re.sub(\"([x#][A-Za-z0-9]+)\",\" \", text).split())\n",
    "\n",
    "def remove_tab(text):\n",
    "    return text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n",
    "\n",
    "def remove_tab2(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_rt(text):\n",
    "    return text.replace('RT',\" \")\n",
    "\n",
    "def remove_mention(text):\n",
    "    return ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n",
    "\n",
    "def remove_incomplete_url(text):\n",
    "    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def change_stripe(text):\n",
    "    return text.replace('-',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "def remove_excessive_dot(text):\n",
    "    return text.replace('..',\" \")\n",
    "\n",
    "def lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+',' ',text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"_\", \"\") # don't remove hyphens\n",
    "    pattern = r\"[{}]\".format(remove) # create the pattern\n",
    "    return re.sub(pattern, \"\", text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947fb34-f7c8-4de0-b5b6-a794e5c93d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "final_string = []\n",
    "s = \"\"\n",
    "for text in df['Length_Text'].values:\n",
    "    filteredSentence = []\n",
    "    EachReviewText = \"\"\n",
    "    proc = remove_rt(text)\n",
    "    proc = lower(proc)\n",
    "    proc = change_stripe(proc)\n",
    "    proc = remove_emoji_alzami(proc)\n",
    "    proc = remove_tab(proc)\n",
    "    proc = remove_tab2(proc)\n",
    "    proc = non_ascii(proc)\n",
    "    proc = remove_incomplete_url(proc)\n",
    "    proc = remove_excessive_dot(proc)\n",
    "    proc = remove_whitespace_LT(proc)\n",
    "    proc = remove_whitespace_multiple(proc)\n",
    "    proc = remove_single_char(proc)\n",
    "    proc = space_punctuation(proc)\n",
    "    proc = remove_punctuation(proc)\n",
    "    proc = remove_space_alzami(proc)\n",
    "    proc = bersih_data(proc)\n",
    "    proc = remove_number_eks(proc)\n",
    "    proc = remove_angka(proc) \n",
    "    proc = remove_URL_eks(proc)\n",
    "    EachReviewText = proc\n",
    "    final_string.append(EachReviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fdc148-b600-46ba-9cbc-d3c73a827df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"step01\"] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a1a062-3ad5-4a3b-bcb3-a93e2320925e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64198e79-c6d8-4da7-b514-a7d40b1c46bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
